{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332f201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: input\\surah1-ayat1.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chains import LLMChain \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "MODEL_NAME = \"llama3\"  # Or any model supported by Ollama\n",
    "INPUT_DIR = \"input\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "# === LLM SETUP ===\n",
    "llm = ChatOllama(model=MODEL_NAME)\n",
    "\n",
    "# === PROMPT TEMPLATE ===\n",
    "template = \"\"\"\n",
    "You are an expert Arabic linguist and translator.\n",
    "1. Correct any grammatical, orthographic, or linguistic errors in the Arabic input.\n",
    "2. Translate the corrected text into fluent English.\n",
    "\n",
    "Return the result in this format:\n",
    "Corrected Arabic: ...\n",
    "English Translation: ...\n",
    "\n",
    "Arabic Text:\n",
    "{input_text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "chain = prompt | llm\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "\n",
    "def load_text_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def split_paragraphs(text):\n",
    "    # Split on newlines, but preserve order\n",
    "    return [p.strip() for p in text.split('\\n') if p.strip()]\n",
    "\n",
    "def process_paragraph(paragraph):\n",
    "    try:\n",
    "        result = chain.invoke({\"input_text\":paragraph})\n",
    "        response_text = result.content if hasattr(result, \"content\") else str(result)\n",
    "\n",
    "        corrected = response_text.split(\"Corrected Arabic:\")[1].split(\"English Translation:\")[0].strip()\n",
    "        translation = response_text.split(\"English Translation:\")[1].strip()\n",
    "        return {\n",
    "            \"original\": paragraph,\n",
    "            \"corrected_arabic\": corrected,\n",
    "            \"english_translation\": translation\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"original\": paragraph,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def process_file(filepath):\n",
    "    print(f\"Processing: {filepath}\")\n",
    "    text = load_text_file(filepath)\n",
    "    paragraphs = split_paragraphs(text)\n",
    "    results = [process_paragraph(p) for p in paragraphs]\n",
    "    return results\n",
    "\n",
    "def save_results(filename, results):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    base = os.path.basename(filename)\n",
    "    output_path = os.path.join(OUTPUT_DIR, base.replace(\".txt\", \"_output.json\"))\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "# === MAIN ===\n",
    "\n",
    "def main():\n",
    "    files = [f for f in os.listdir(INPUT_DIR) if f.endswith(\".txt\")]\n",
    "    for file in files:\n",
    "        path = os.path.join(INPUT_DIR, file)\n",
    "        results = process_file(path)\n",
    "        save_results(file, results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
