{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove csv files from tafsir folder\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base_folder = Path('tafsir')\n",
    "for auth_folder in base_folder.iterdir():\n",
    "    for csv_file in auth_folder.glob(\"*.csv\"):\n",
    "        os.remove(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01287c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tafsir text from json file and save it to a text file\n",
    "import os\n",
    "import json\n",
    "\n",
    "base_dir = \"tafsir\"\n",
    "\n",
    "for author in os.listdir(base_dir):\n",
    "    author_dir = os.path.join(base_dir, author)\n",
    "    if not os.path.isdir(author_dir):\n",
    "        continue\n",
    "    for filename in os.listdir(author_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            surah_number = filename.replace(\".json\", \"\")\n",
    "            json_path = os.path.join(author_dir, filename)\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            for item in data:\n",
    "                ayah_number = item[\"ayah_number\"]\n",
    "                txt_path = os.path.join(author_dir, f\"{surah_number}_{ayah_number}.txt\")\n",
    "                tafsir_text = item.pop(\"tafsir_text\", \"\")\n",
    "                if tafsir_text:\n",
    "                    with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                        txt_file.write(tafsir_text)\n",
    "                    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if tafsir text has starting index and ending index then remove it\n",
    "import os\n",
    "\n",
    "base_dir = \"tafsir\"\n",
    "\n",
    "for author in os.listdir(base_dir):\n",
    "    author_dir = os.path.join(base_dir, author)\n",
    "    if not os.path.isdir(author_dir):\n",
    "        continue\n",
    "    for filename in os.listdir(author_dir):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            txt_path = os.path.join(author_dir, filename)\n",
    "            with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            if content.find(\"﴿\") != -1:\n",
    "                print(f\"Processing {txt_path}\")\n",
    "                # remove everything before the first occurrence of \"﴿\"\n",
    "                content = content[content.find(\"﴿\"):]\n",
    "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cfe1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if tafsir text in json file has starting index and ending index then remove it\n",
    "import os\n",
    "import json\n",
    "\n",
    "base_dir = \"tafsir\"\n",
    "\n",
    "for author in os.listdir(base_dir):\n",
    "    author_dir = os.path.join(base_dir, author)\n",
    "    if not os.path.isdir(author_dir):\n",
    "        continue\n",
    "    for filename in os.listdir(author_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            json_path = os.path.join(author_dir, filename)\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_content = json.load(f)\n",
    "            if isinstance(json_content, list):\n",
    "                for item in json_content:\n",
    "                    tafsir_text = item.get(\"tafsir_text\", \"\")\n",
    "                    if tafsir_text:\n",
    "                        if tafsir_text.find(\"﴿\") != -1:\n",
    "                            # remove everything before the first occurrence of \"﴿\"\n",
    "                            tafsir_text = tafsir_text[tafsir_text.find(\"﴿\"):]\n",
    "                        item[\"tafsir_text\"] = tafsir_text\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(json_content, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dff488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split long text by words then create chunks of acceptable characters per api request\n",
    "with open(\"000 - INTRODUCTION TO AL-QURAN-01_chunk_01.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "words = text.split()\n",
    "print(f\"Total characters: {len(text)}\")\n",
    "print(f\"Total words: {len(words)}\")\n",
    "\n",
    "sentences = []\n",
    "i = 0\n",
    "while i < len(words):\n",
    "    sentence = []\n",
    "    while i < len(words) and len(\" \".join(sentence + words[i:i+1])) <= 3000:\n",
    "        sentence.append(words[i])\n",
    "        i += 1\n",
    "    sentences.append(\" \".join(sentence))\n",
    "\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence[:50]}... ({len(sentence)} characters)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5525d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Urdu Lectures to English (single file)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.translate_from_file(\"001 - SURAH AL-FATIHA_01.txt\", \"001 - SURAH AL-FATIHA_01_en.txt\", 'ur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Urdu Lectures to English (batch processing)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.batch_translate_files(\"lectures/\", \"lectures_translated/\", 'ur')        # English\n",
    "result = translator.batch_translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'fr')  # French\n",
    "result = translator.batch_translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'de')  # German\n",
    "result = translator.batch_translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'es')  # Spanish\n",
    "result = translator.batch_translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'ar')  # Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ffb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Arabic Tafsir to English (single file)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.translate_from_file(\"surah1-ayat1.txt\", \"surah1-ayat1_en.txt\", 'ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Arabic Tafsir to English (batch processing)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.batch_translate_files(\"tafsir/\", \"tafsir_translated/\", 'ar')        # English"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
