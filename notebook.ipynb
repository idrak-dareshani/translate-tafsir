{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove csv files from tafsir folder\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "base_folder = Path('tafsir')\n",
    "for auth_folder in base_folder.iterdir():\n",
    "    for csv_file in auth_folder.glob(\"*.csv\"):\n",
    "        os.remove(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01287c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tafsir text from json file and save it to a text file\n",
    "import os\n",
    "import json\n",
    "\n",
    "base_dir = \"tafsir\"\n",
    "\n",
    "for author in os.listdir(base_dir):\n",
    "    author_dir = os.path.join(base_dir, author)\n",
    "    if not os.path.isdir(author_dir):\n",
    "        continue\n",
    "    for filename in os.listdir(author_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            surah_number = filename.replace(\".json\", \"\")\n",
    "            json_path = os.path.join(author_dir, filename)\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            for item in data:\n",
    "                ayah_number = item[\"ayah_number\"]\n",
    "                txt_path = os.path.join(author_dir, f\"{surah_number}_{ayah_number}.txt\")\n",
    "                tafsir_text = item.pop(\"tafsir_text\", \"\")\n",
    "                if tafsir_text:\n",
    "                    with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                        txt_file.write(tafsir_text)\n",
    "                    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if tafsir text has starting index and ending index then remove it\n",
    "import os\n",
    "\n",
    "base_dir = \"tafsir\"\n",
    "\n",
    "for author in os.listdir(base_dir):\n",
    "    author_dir = os.path.join(base_dir, author)\n",
    "    if not os.path.isdir(author_dir):\n",
    "        continue\n",
    "    for filename in os.listdir(author_dir):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            txt_path = os.path.join(author_dir, filename)\n",
    "            with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            if content.find(\"﴿\") != -1:\n",
    "                print(f\"Processing {txt_path}\")\n",
    "                # remove everything before the first occurrence of \"﴿\"\n",
    "                content = content[content.find(\"﴿\"):]\n",
    "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cfe1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if tafsir text in json file has starting index and ending index then remove it\n",
    "import os\n",
    "import json\n",
    "\n",
    "base_dir = \"tafsir\"\n",
    "\n",
    "for author in os.listdir(base_dir):\n",
    "    author_dir = os.path.join(base_dir, author)\n",
    "    if not os.path.isdir(author_dir):\n",
    "        continue\n",
    "    for filename in os.listdir(author_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            json_path = os.path.join(author_dir, filename)\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_content = json.load(f)\n",
    "            if isinstance(json_content, list):\n",
    "                for item in json_content:\n",
    "                    tafsir_text = item.get(\"tafsir_text\", \"\")\n",
    "                    if tafsir_text:\n",
    "                        if tafsir_text.find(\"﴿\") != -1:\n",
    "                            # remove everything before the first occurrence of \"﴿\"\n",
    "                            tafsir_text = tafsir_text[tafsir_text.find(\"﴿\"):]\n",
    "                        item[\"tafsir_text\"] = tafsir_text\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(json_content, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dff488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split long text by words then create chunks of acceptable characters per api request\n",
    "with open(\"000 - INTRODUCTION TO AL-QURAN-01_chunk_01.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "words = text.split()\n",
    "print(f\"Total characters: {len(text)}\")\n",
    "print(f\"Total words: {len(words)}\")\n",
    "\n",
    "sentences = []\n",
    "i = 0\n",
    "while i < len(words):\n",
    "    sentence = []\n",
    "    while i < len(words) and len(\" \".join(sentence + words[i:i+1])) <= 3000:\n",
    "        sentence.append(words[i])\n",
    "        i += 1\n",
    "    sentences.append(\" \".join(sentence))\n",
    "\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence[:50]}... ({len(sentence)} characters)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5525d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 15:18:24,434 - INFO - Multi-language Tafsir Translator initialized\n",
      "2025-07-18 15:18:24,467 - INFO - Read 19473 characters from surah1-lecture.txt\n",
      "2025-07-18 15:18:24,471 - INFO - Starting tafsir translation with automatic language detection...\n",
      "2025-07-18 15:18:24,473 - INFO - Source language: Urdu (ur)\n",
      "2025-07-18 15:18:24,494 - INFO - Text split into 7 chunks using newline and word-based strategy.\n",
      "2025-07-18 15:18:24,498 - INFO - Text split into 7 chunks\n",
      "2025-07-18 15:18:24,500 - INFO - Translating chunk 1/7...\n",
      "2025-07-18 15:18:30,879 - INFO - Translating chunk 2/7...\n",
      "2025-07-18 15:18:38,907 - INFO - Translating chunk 3/7...\n",
      "2025-07-18 15:18:44,972 - INFO - Translating chunk 4/7...\n",
      "2025-07-18 15:18:51,120 - INFO - Translating chunk 5/7...\n",
      "2025-07-18 15:18:53,267 - INFO - Translating chunk 6/7...\n",
      "2025-07-18 15:18:59,623 - INFO - Translating chunk 7/7...\n",
      "2025-07-18 15:19:01,674 - INFO - Translation completed! Success rate: 100.0%\n",
      "2025-07-18 15:19:01,717 - INFO - Translation saved to surah1-lecture_en.txt\n"
     ]
    }
   ],
   "source": [
    "# Translate Urdu Lectures to English (single file)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.translate_file(\"surah1-lecture.txt\", \"surah1-lecture_en.txt\", 'ur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Urdu Lectures to English (batch processing)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.translate_files(\"lectures/\", \"lectures_translated/\", 'ur')        # English\n",
    "# result = translator.translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'fr')  # French\n",
    "# result = translator.translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'de')  # German\n",
    "# result = translator.translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'es')  # Spanish\n",
    "# result = translator.translate_files(\"lectures/\", \"lectures_translated/\", 'ur', 'ar')  # Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ffb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Arabic Tafsir to English (single file)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.translate_file(\"surah1-ayat1.txt\", \"surah1-ayat1_en.txt\", \"ar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate Arabic Tafsir to English (batch processing)\n",
    "from translate import TafsirTranslator\n",
    "\n",
    "translator = TafsirTranslator()\n",
    "result = translator.translate_files(\"tafsir/\", \"tafsir_translated/\", 'ar')        # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b621ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Arabic Example ===\n",
      "Text with placeholders: هذا نص عربي __1__ ونص آخر يجب ترجمته\n",
      "Translated text: This is an Arabic text __1__ and another text that must be translated\n",
      "Final text: This is an Arabic textوَاتَّقُواْ اللّهَ الَّذِي تَسَاءلُونَ بِهِ وَالأَرْحَامَand another text that must be translated\n",
      "\n",
      "=== Urdu Example ===\n",
      "Text with placeholders: یہ اردو کا متن ہے __1__ اور یہ محفوظ رہنا چاہیے\n",
      "Translated text: This is the text of Urdu __1__ and it must be safe\n",
      "Final text: This is the text of Urduاللہ تعالیٰand it must be safe\n",
      "\n",
      "=== Testing Different Placeholder Formats ===\n",
      "\n",
      "Testing format: PLACEHOLDER_{id}_END\n",
      "With placeholder: نص تجريبي PLACEHOLDER_1_END نص آخر\n",
      "Simulated translation: test text PLACEHOLDER_1_END other text\n",
      "Restored: test textمحميother text\n",
      "\n",
      "Testing format: [PH{id:03d}]\n",
      "With placeholder: نص تجريبي [PH001] نص آخر\n",
      "Simulated translation: test text [PH001] other text\n",
      "Restored: test textمحميother text\n",
      "\n",
      "Testing format: <ph id=\"{id}\"/>\n",
      "With placeholder: نص تجريبي <ph id=\"1\"/> نص آخر\n",
      "Simulated translation: test text <ph id=\"1\"/> other text\n",
      "Restored: test textمحميother text\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "class TranslationPlaceholderManager:\n",
    "    def __init__(self, placeholder_format=\"PLACEHOLDER_{id}_END\"):\n",
    "        \"\"\"\n",
    "        Initialize placeholder manager\n",
    "        \n",
    "        Args:\n",
    "            placeholder_format: Format string with {id} where counter goes\n",
    "                               Options: \"PLACEHOLDER_{id}_END\", \"[PH{id:03d}]\", \"<ph id=\\\"{id}\\\"/>\"\n",
    "        \"\"\"\n",
    "        self.placeholder_format = placeholder_format\n",
    "        self.placeholder_map: Dict[str, str] = {}\n",
    "        self.counter = 0\n",
    "        \n",
    "    def add_placeholder(self, original_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Add text to be protected and return its placeholder\n",
    "        \n",
    "        Args:\n",
    "            original_text: Text to protect from translation\n",
    "            \n",
    "        Returns:\n",
    "            Generated placeholder string\n",
    "        \"\"\"\n",
    "        self.counter += 1\n",
    "        placeholder = self.placeholder_format.format(id=self.counter)\n",
    "        self.placeholder_map[placeholder] = original_text\n",
    "        return placeholder\n",
    "    \n",
    "    def insert_placeholders(self, text: str, protected_texts: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Insert placeholders for multiple protected texts\n",
    "        \n",
    "        Args:\n",
    "            text: Original text\n",
    "            protected_texts: List of text segments to protect\n",
    "            \n",
    "        Returns:\n",
    "            Text with placeholders inserted\n",
    "        \"\"\"\n",
    "        result = text\n",
    "        for protected_text in protected_texts:\n",
    "            placeholder = self.add_placeholder(protected_text)\n",
    "            result = result.replace(protected_text, placeholder)\n",
    "        return result\n",
    "    \n",
    "    def restore_placeholders(self, translated_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Replace placeholders with original protected text\n",
    "        \n",
    "        Args:\n",
    "            translated_text: Text returned from translator\n",
    "            \n",
    "        Returns:\n",
    "            Text with placeholders restored to original content\n",
    "        \"\"\"\n",
    "        result = translated_text\n",
    "        \n",
    "        # Create flexible regex patterns for each placeholder\n",
    "        for placeholder, original_text in self.placeholder_map.items():\n",
    "            # Create a flexible pattern that handles potential translation corruption\n",
    "            flexible_pattern = self._create_flexible_pattern(placeholder)\n",
    "            \n",
    "            # Replace all matches with original text\n",
    "            result = flexible_pattern.sub(original_text, result)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def _create_flexible_pattern(self, placeholder: str) -> re.Pattern:\n",
    "        \"\"\"\n",
    "        Create a flexible regex pattern that can handle translator modifications\n",
    "        \n",
    "        Args:\n",
    "            placeholder: Original placeholder string\n",
    "            \n",
    "        Returns:\n",
    "            Compiled regex pattern\n",
    "        \"\"\"\n",
    "        # Extract the core parts that are less likely to change\n",
    "        if \"PLACEHOLDER_\" in placeholder and \"_END\" in placeholder:\n",
    "            # For PLACEHOLDER_001_END format\n",
    "            match = re.search(r'PLACEHOLDER_(\\d+)_END', placeholder)\n",
    "            if match:\n",
    "                number = match.group(1)\n",
    "                # Allow for case changes, spacing, and minor modifications\n",
    "                pattern = rf'(?i)\\s*PLACEHOLDER\\s*[_\\s]*{re.escape(number)}[_\\s]*END\\s*'\n",
    "        \n",
    "        elif placeholder.startswith('[PH') and placeholder.endswith(']'):\n",
    "            # For [PH001] format\n",
    "            match = re.search(r'\\[PH(\\d+)\\]', placeholder)\n",
    "            if match:\n",
    "                number = match.group(1)\n",
    "                # Allow for spacing and case changes\n",
    "                pattern = rf'(?i)\\s*\\[?\\s*PH\\s*{re.escape(number)}\\s*\\]?\\s*'\n",
    "        \n",
    "        elif '<ph id=' in placeholder:\n",
    "            # For <ph id=\"001\"/> format\n",
    "            match = re.search(r'<ph id=\"(\\d+)\"/>', placeholder)\n",
    "            if match:\n",
    "                number = match.group(1)\n",
    "                # Allow for various XML formatting changes\n",
    "                pattern = rf'(?i)\\s*<\\s*ph\\s+id\\s*=\\s*[\"\\']?\\s*{re.escape(number)}\\s*[\"\\']?\\s*/?\\s*>\\s*'\n",
    "        \n",
    "        else:\n",
    "            # Fallback: escape the entire placeholder and allow minor modifications\n",
    "            escaped = re.escape(placeholder)\n",
    "            pattern = rf'(?i)\\s*{escaped}\\s*'\n",
    "        \n",
    "        return re.compile(pattern)\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Reset the placeholder manager\"\"\"\n",
    "        self.placeholder_map.clear()\n",
    "        self.counter = 0\n",
    "\n",
    "\n",
    "# Example usage functions\n",
    "def translate_with_protection(text: str, protected_segments: List[str], \n",
    "                            source_lang: str = 'auto', target_lang: str = 'en') -> str:\n",
    "    \"\"\"\n",
    "    Translate text while protecting certain segments\n",
    "    \n",
    "    Args:\n",
    "        text: Text to translate\n",
    "        protected_segments: List of text segments to protect from translation\n",
    "        source_lang: Source language code\n",
    "        target_lang: Target language code\n",
    "        \n",
    "    Returns:\n",
    "        Translated text with protected segments restored\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize placeholder manager\n",
    "    pm = TranslationPlaceholderManager(\"__{id}__\")\n",
    "    \n",
    "    # Insert placeholders\n",
    "    text_with_placeholders = pm.insert_placeholders(text, protected_segments)\n",
    "    \n",
    "    print(f\"Text with placeholders: {text_with_placeholders}\")\n",
    "    \n",
    "    # Translate\n",
    "    translator = GoogleTranslator(source=source_lang, target=target_lang)\n",
    "    try:\n",
    "        translated_text = translator.translate(text_with_placeholders)\n",
    "        print(f\"Translated text: {translated_text}\")\n",
    "        \n",
    "        # Restore placeholders\n",
    "        final_text = pm.restore_placeholders(translated_text)\n",
    "        print(f\"Final text: {final_text}\")\n",
    "        \n",
    "        return final_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return text\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Arabic text with Quranic verse to protect\n",
    "    arabic_text = \"هذا نص عربي وَاتَّقُواْ اللّهَ الَّذِي تَسَاءلُونَ بِهِ وَالأَرْحَامَ ونص آخر يجب ترجمته\"\n",
    "    protected_verse = \"وَاتَّقُواْ اللّهَ الَّذِي تَسَاءلُونَ بِهِ وَالأَرْحَامَ\"\n",
    "    \n",
    "    print(\"=== Arabic Example ===\")\n",
    "    result = translate_with_protection(arabic_text, [protected_verse], 'ar', 'en')\n",
    "    \n",
    "    # Example 2: Urdu text\n",
    "    urdu_text = \"یہ اردو کا متن ہے اللہ تعالیٰ اور یہ محفوظ رہنا چاہیے\"\n",
    "    protected_text = \"اللہ تعالیٰ\"\n",
    "    \n",
    "    print(\"\\n=== Urdu Example ===\")\n",
    "    result2 = translate_with_protection(urdu_text, [protected_text], 'ur', 'en')\n",
    "    \n",
    "    # Example 3: Testing different placeholder formats\n",
    "    print(\"\\n=== Testing Different Placeholder Formats ===\")\n",
    "    \n",
    "    formats = [\n",
    "        \"PLACEHOLDER_{id}_END\",\n",
    "        \"[PH{id:03d}]\", \n",
    "        \"<ph id=\\\"{id}\\\"/>\"\n",
    "    ]\n",
    "    \n",
    "    for fmt in formats:\n",
    "        print(f\"\\nTesting format: {fmt}\")\n",
    "        pm = TranslationPlaceholderManager(fmt)\n",
    "        test_text = \"نص تجريبي محمي نص آخر\"\n",
    "        protected = \"محمي\"\n",
    "        \n",
    "        with_ph = pm.insert_placeholders(test_text, [protected])\n",
    "        print(f\"With placeholder: {with_ph}\")\n",
    "        \n",
    "        # Simulate what might come back from translator\n",
    "        simulated_return = with_ph.replace(\"نص تجريبي\", \"test text\").replace(\"نص آخر\", \"other text\")\n",
    "        print(f\"Simulated translation: {simulated_return}\")\n",
    "        \n",
    "        restored = pm.restore_placeholders(simulated_return)\n",
    "        print(f\"Restored: {restored}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
